{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f364e5-0675-4997-a6a5-539705f7c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation,Reshape,Convolution2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,ConfusionMatrixDisplay\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "os.chdir(\"/Dataset\")\n",
    "numbers=os.listdir()\n",
    "\n",
    "if os.path.isdir(\"train/0\") is False:\n",
    "    os.mkdir(\"train\")\n",
    "    os.mkdir(\"test\")\n",
    "    os.mkdir(\"valid\")\n",
    "    \n",
    "    for i in numbers:\n",
    "        shutil.move(f\"{i}\",\"train\")\n",
    "        os.mkdir(f\"valid/{i}\")\n",
    "        os.mkdir(f\"test/{i}\")\n",
    "        for k in random.sample(os.listdir(f\"train/{i}\"),30):\n",
    "            shutil.move(f\"train/{i}/{k}\",f\"valid/{i}\")\n",
    "        for j in random.sample(os.listdir(f\"train/{i}\"),5):\n",
    "            shutil.move(f\"train/{i}/{j}\",f\"test/{i}\")\n",
    "os.chdir(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f6b9a9-b9ef-4a96-a083-8bb98715260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input)\n",
    "train_batches=train_batches.flow_from_directory(\n",
    "    directory=\"train\",batch_size=10,target_size=(224,224))\n",
    "valid_batches=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "    directory=\"valid\",batch_size=10,target_size=(224,224))\n",
    "test_batches=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "    directory=\"test\",batch_size=10,target_size=(224,224),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98b55673-f163-4640-aa1f-48160029d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_batches.n==1712\n",
    "assert valid_batches.n==300\n",
    "assert test_batches.n==50\n",
    "assert test_batches.num_classes==valid_batches.num_classes==train_batches.num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84231820-505e-4d57-ae03-dac1ca33b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile=tf.keras.applications.mobilenet.MobileNet()\n",
    "mobile.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d77199f1-0880-49d5-a20f-946201b6e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=mobile.layers[-5].output\n",
    "output=tf.keras.layers.Flatten()(x)\n",
    "outputs=Dense(units=10,activation=\"softmax\")(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31dd2b68-007e-443a-a0bc-6b995c039753",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=mobile.input,outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db08a71-0449-4f49-bf74-8eab8bfeb28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[0:-23]:\n",
    "    layer.trainable=False\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c7a6e-0091-4613-bfba-a59e2b386962",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.fit(x=train_batches,validation_data=valid_batches,epochs=30,verbose=2)\n",
    "model.save(\"/model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d974b61f-a04b-4ab7-9435-1aa2017ba26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model1=load_model(\"model.keras\")\n",
    "model1.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b8afd9b-207c-4e1b-85c8-0e852305ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model1.predict(test_batches,verbose=0)\n",
    "rounded=np.round(predictions)\n",
    "cm=confusion_matrix(y_true=test_batches.classes,y_pred=np.argmax(rounded,axis=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d768ea38-37b9-413c-98af-c7a42466bc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display=ConfusionMatrixDisplay(cm)\n",
    "display.plot()\n",
    "accuracy_score(test_batches.classes,np.argmax(rounded,axis=-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
